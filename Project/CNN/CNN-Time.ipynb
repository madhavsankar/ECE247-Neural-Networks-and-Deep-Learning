{"cells":[{"cell_type":"markdown","metadata":{"id":"N-HEWfdk8jfp"},"source":["## (i) Importing the necessary packages"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"NF0CH5ws8jfq","executionInfo":{"status":"ok","timestamp":1647284045585,"user_tz":420,"elapsed":174,"user":{"displayName":"MADHAV SANKAR KRISHNAKUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0m0fuT--5uwkw6pMCZZIpUzOWdwvpSp5QY_fR=s64","userId":"01623580652319682030"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Flatten,Dropout\n","from keras.layers import Conv2D,BatchNormalization,MaxPooling2D,Reshape\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["import sys\n","runningOnColab = 'google.colab' in sys.modules\n","if runningOnColab:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd '/content/drive/Shareddrives/ECE247/Project'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IsiwV5ZB8n15","executionInfo":{"status":"ok","timestamp":1647284046438,"user_tz":420,"elapsed":734,"user":{"displayName":"MADHAV SANKAR KRISHNAKUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0m0fuT--5uwkw6pMCZZIpUzOWdwvpSp5QY_fR=s64","userId":"01623580652319682030"}},"outputId":"7bb80d90-5206-4a5c-e726-51562df1a80d"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/Shareddrives/ECE247/Project\n"]}]},{"cell_type":"markdown","metadata":{"id":"La_xcF-Y8jfr"},"source":["## (ii) Preprocessing the dataset and preparing the training, validation, and test datasets"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"Gni3feQJ8jfs","executionInfo":{"status":"ok","timestamp":1647284047285,"user_tz":420,"elapsed":850,"user":{"displayName":"MADHAV SANKAR KRISHNAKUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0m0fuT--5uwkw6pMCZZIpUzOWdwvpSp5QY_fR=s64","userId":"01623580652319682030"}}},"outputs":[],"source":["## Loading and visualizing the data\n","## Loading the dataset\n","X_test_load = np.load(\"X_test.npy\")\n","y_test_load = np.load(\"y_test.npy\")\n","person_train_valid = np.load(\"person_train_valid.npy\")\n","X_train_valid_load = np.load(\"X_train_valid.npy\")\n","y_train_valid_load = np.load(\"y_train_valid.npy\")\n","person_test = np.load(\"person_test.npy\")\n","\n","person_train_valid = np.squeeze(person_train_valid)\n","person_test = np.squeeze(person_test)\n","\n","y_train_valid_load -= 769\n","y_test_load -= 769"]},{"cell_type":"markdown","metadata":{"id":"CpKNfviF8jfw"},"source":["## (iii)(CNN) Defining the architecture of a basic CNN model"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"Nqpw0N_L8jfx","executionInfo":{"status":"ok","timestamp":1647284047285,"user_tz":420,"elapsed":7,"user":{"displayName":"MADHAV SANKAR KRISHNAKUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0m0fuT--5uwkw6pMCZZIpUzOWdwvpSp5QY_fR=s64","userId":"01623580652319682030"}}},"outputs":[],"source":["def create_model(t):\n","    # Building the CNN model using sequential class\n","    basic_cnn_model = Sequential()\n","\n","    # Conv. block 1\n","    basic_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(t,1,22)))\n","    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n","    basic_cnn_model.add(BatchNormalization())\n","    basic_cnn_model.add(Dropout(0.5))\n","\n","    # Conv. block 2\n","    basic_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n","    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n","    basic_cnn_model.add(BatchNormalization())\n","    basic_cnn_model.add(Dropout(0.5))\n","\n","    # Conv. block 3\n","    basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n","    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n","    basic_cnn_model.add(BatchNormalization())\n","    basic_cnn_model.add(Dropout(0.5))\n","\n","    # Conv. block 4\n","    basic_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n","    basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n","    basic_cnn_model.add(BatchNormalization())\n","    basic_cnn_model.add(Dropout(0.5))\n","\n","    # Output layer with Softmax activation\n","    basic_cnn_model.add(Flatten()) # Flattens the input\n","    basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n","\n","    return basic_cnn_model\n"]},{"cell_type":"markdown","metadata":{"id":"wz0KVDZh8jfx"},"source":["## (iv)(CNN) Defining the hyperparameters of the basic CNN model"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJ8ILLRE8jfx","executionInfo":{"status":"ok","timestamp":1647284047286,"user_tz":420,"elapsed":6,"user":{"displayName":"MADHAV SANKAR KRISHNAKUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0m0fuT--5uwkw6pMCZZIpUzOWdwvpSp5QY_fR=s64","userId":"01623580652319682030"}},"outputId":"bf148ee5-172a-4422-f68e-8a6321cecc4c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}],"source":["# Model parameters\n","learning_rate = 1e-3\n","epochs = 50\n","cnn_optimizer = tf.keras.optimizers.Adam(lr=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"RBYxC8wq8jfu"},"source":["![EEG_prep.png](attachment:EEG_prep.png)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"jkRBH1tE8jfu","executionInfo":{"status":"ok","timestamp":1647284047286,"user_tz":420,"elapsed":4,"user":{"displayName":"MADHAV SANKAR KRISHNAKUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0m0fuT--5uwkw6pMCZZIpUzOWdwvpSp5QY_fR=s64","userId":"01623580652319682030"}}},"outputs":[],"source":["def data_prep(X, y, person, t, sub_sample, average, noise):\n","    total_X = None\n","    total_y = None\n","    total_person = None\n","\n","    # Trimming the data (sample,22,1000) -> (sample,22,500)\n","    X = X[:,:,0:t]\n","    \n","    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n","    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n","    \n","    total_X = X_max\n","    total_y = y\n","    total_person = person\n","    \n","    # Averaging + noise \n","    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n","    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n","    \n","    total_X = np.vstack((total_X, X_average))\n","    total_y = np.hstack((total_y, y))\n","    total_person = np.hstack((total_person, person))\n","    \n","    # Subsampling\n","    \n","    for i in range(sub_sample):\n","        \n","        X_subsample = X[:, :, i::sub_sample] + \\\n","                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n","            \n","        total_X = np.vstack((total_X, X_subsample))\n","        total_y = np.hstack((total_y, y))\n","        total_person = np.hstack((total_person, person))\n","        \n","    return total_X, total_y, total_person \n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1IAmC0a8jfv","executionInfo":{"status":"ok","timestamp":1647284317888,"user_tz":420,"elapsed":270605,"user":{"displayName":"MADHAV SANKAR KRISHNAKUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0m0fuT--5uwkw6pMCZZIpUzOWdwvpSp5QY_fR=s64","userId":"01623580652319682030"}},"outputId":"57065b56-b40b-4e55-a228-9c60286c41e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Time:  400\n","Test accuracy of the basic CNN model: 0.709932267665863\n","Time:  500\n","Test accuracy of the basic CNN model: 0.7093679308891296\n","Time:  600\n","Test accuracy of the basic CNN model: 0.6867945790290833\n","Time:  700\n","Test accuracy of the basic CNN model: 0.6828442215919495\n"]}],"source":["\n","## Preprocessing the dataset\n","times = [400, 500, 600, 700]\n","\n","for t in times:\n","    print('Time: ', t)\n","    X_train_valid_prep, y_train_valid_prep, person_train_valid_prep = data_prep(X_train_valid_load, y_train_valid_load, person_train_valid, t, 2, 2, True)\n","    X_test_prep, y_test_prep, person_test_prep = data_prep(X_test_load, y_test_load, person_test, t, 2, 2, True)\n","\n","    ## Random splitting and reshaping the data\n","    # First generating the training and validation indices using random splitting\n","    ind_valid = np.random.choice(8460, 1500, replace=False)\n","    ind_train = np.array(list(set(range(8460)).difference(set(ind_valid))))\n","\n","    # Creating the training and validation sets using the generated indices\n","    (x_train, x_valid) = X_train_valid_prep[ind_train], X_train_valid_prep[ind_valid] \n","    (y_train, y_valid) = y_train_valid_prep[ind_train], y_train_valid_prep[ind_valid]\n","    (person_train, person_valid) = person_train_valid_prep[ind_train], person_train_valid_prep[ind_valid]\n","\n","\n","    # Converting the labels to categorical variables for multiclass classification\n","    y_train = to_categorical(y_train, 4)\n","    y_valid = to_categorical(y_valid, 4)\n","    y_test = to_categorical(y_test_prep, 4)\n","\n","    person_test = person_test_prep\n","\n","    # Adding width of the segment to be 1\n","    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n","    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n","    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n","\n","    # Reshaping the training and validation dataset\n","    x_train = np.swapaxes(x_train, 1,3)\n","    x_train = np.swapaxes(x_train, 1,2)\n","    x_valid = np.swapaxes(x_valid, 1,3)\n","    x_valid = np.swapaxes(x_valid, 1,2)\n","    x_test = np.swapaxes(x_test, 1,3)\n","    x_test = np.swapaxes(x_test, 1,2)\n","\n","    basic_cnn_model = create_model(t // 2)\n","    # Compiling the model\n","    basic_cnn_model.compile(loss='categorical_crossentropy',\n","                    optimizer=cnn_optimizer,\n","                    metrics=['accuracy'])\n","\n","    # Training and validating the model\n","    basic_cnn_model_results = basic_cnn_model.fit(x_train,\n","                y_train,\n","                batch_size=64,\n","                epochs=epochs,\n","                validation_data=(x_valid, y_valid), verbose=False)\n","\n","    cnn_score = basic_cnn_model.evaluate(x_test, y_test, verbose=0)\n","    print('Test accuracy of the basic CNN model:',cnn_score[1]) \n","\n","\n","    \n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"CNN-Time.ipynb","provenance":[{"file_id":"1svFJxNsNNy9q8WQ6EaMtH7m7rjCJSAEN","timestamp":1647213628422}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}